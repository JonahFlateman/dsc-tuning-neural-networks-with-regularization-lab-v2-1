{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_Complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(10000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df['Product']\n",
    "X = df['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:,:,1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:,:,1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 6s 109us/step - loss: 1.8986 - acc: 0.2073 - val_loss: 1.8378 - val_acc: 0.2870\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 1s 23us/step - loss: 1.6969 - acc: 0.4008 - val_loss: 1.5371 - val_acc: 0.4940\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.3609 - acc: 0.5717 - val_loss: 1.2127 - val_acc: 0.5990\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.0813 - acc: 0.6546 - val_loss: 0.9823 - val_acc: 0.6630\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.9014 - acc: 0.6972 - val_loss: 0.8468 - val_acc: 0.7080\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.7949 - acc: 0.7230 - val_loss: 0.7724 - val_acc: 0.7250\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.7295 - acc: 0.7397 - val_loss: 0.7240 - val_acc: 0.7360\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6858 - acc: 0.7504 - val_loss: 0.6884 - val_acc: 0.7510\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.6541 - acc: 0.7614 - val_loss: 0.6673 - val_acc: 0.7630\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.6294 - acc: 0.7684 - val_loss: 0.6530 - val_acc: 0.7650\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6098 - acc: 0.7762 - val_loss: 0.6356 - val_acc: 0.7730\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5932 - acc: 0.7824 - val_loss: 0.6237 - val_acc: 0.7720\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5791 - acc: 0.7880 - val_loss: 0.6121 - val_acc: 0.7770\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5666 - acc: 0.7927 - val_loss: 0.6034 - val_acc: 0.7850\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5557 - acc: 0.7983 - val_loss: 0.5987 - val_acc: 0.7800\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5458 - acc: 0.8019 - val_loss: 0.5902 - val_acc: 0.7840\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5367 - acc: 0.8060 - val_loss: 0.5891 - val_acc: 0.7880\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5284 - acc: 0.8091 - val_loss: 0.5812 - val_acc: 0.7850\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5205 - acc: 0.8119 - val_loss: 0.5801 - val_acc: 0.7870\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5135 - acc: 0.8158 - val_loss: 0.5750 - val_acc: 0.7880\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5068 - acc: 0.8183 - val_loss: 0.5752 - val_acc: 0.7910\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5007 - acc: 0.8199 - val_loss: 0.5710 - val_acc: 0.7870\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 1s 23us/step - loss: 0.4947 - acc: 0.8232 - val_loss: 0.5781 - val_acc: 0.7870\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.4894 - acc: 0.8249 - val_loss: 0.5636 - val_acc: 0.7930\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4839 - acc: 0.8267 - val_loss: 0.5651 - val_acc: 0.7950\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4791 - acc: 0.8290 - val_loss: 0.5643 - val_acc: 0.7920\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4747 - acc: 0.8305 - val_loss: 0.5629 - val_acc: 0.7930\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.4701 - acc: 0.8325 - val_loss: 0.5582 - val_acc: 0.7950\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.4656 - acc: 0.8341 - val_loss: 0.5602 - val_acc: 0.7980\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4617 - acc: 0.8353 - val_loss: 0.5592 - val_acc: 0.8000\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.4576 - acc: 0.8365 - val_loss: 0.5581 - val_acc: 0.7990\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.4540 - acc: 0.8391 - val_loss: 0.5560 - val_acc: 0.7990\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.4506 - acc: 0.8407 - val_loss: 0.5555 - val_acc: 0.7960\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.4471 - acc: 0.8416 - val_loss: 0.5586 - val_acc: 0.7970\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.4441 - acc: 0.8429 - val_loss: 0.5597 - val_acc: 0.7990\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4407 - acc: 0.8435 - val_loss: 0.5557 - val_acc: 0.7970\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4377 - acc: 0.8456 - val_loss: 0.5546 - val_acc: 0.8010\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4346 - acc: 0.8460 - val_loss: 0.5545 - val_acc: 0.8040\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4316 - acc: 0.8476 - val_loss: 0.5555 - val_acc: 0.7980\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.4292 - acc: 0.8485 - val_loss: 0.5547 - val_acc: 0.8030\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4265 - acc: 0.8488 - val_loss: 0.5582 - val_acc: 0.8020\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.4238 - acc: 0.8502 - val_loss: 0.5559 - val_acc: 0.7960\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4212 - acc: 0.8520 - val_loss: 0.5552 - val_acc: 0.8040\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.4187 - acc: 0.8526 - val_loss: 0.5584 - val_acc: 0.8020\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.4163 - acc: 0.8528 - val_loss: 0.5564 - val_acc: 0.8040\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4140 - acc: 0.8545 - val_loss: 0.5560 - val_acc: 0.8030\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.4117 - acc: 0.8543 - val_loss: 0.5584 - val_acc: 0.8020\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4096 - acc: 0.8553 - val_loss: 0.5649 - val_acc: 0.8010\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4075 - acc: 0.8569 - val_loss: 0.5563 - val_acc: 0.7970\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.4053 - acc: 0.8570 - val_loss: 0.5611 - val_acc: 0.8020\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.4033 - acc: 0.8571 - val_loss: 0.5565 - val_acc: 0.7980\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.4012 - acc: 0.8594 - val_loss: 0.5567 - val_acc: 0.8040\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3991 - acc: 0.8602 - val_loss: 0.5583 - val_acc: 0.7970\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3971 - acc: 0.8603 - val_loss: 0.5574 - val_acc: 0.8030\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.3955 - acc: 0.8608 - val_loss: 0.5610 - val_acc: 0.8000\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3936 - acc: 0.8617 - val_loss: 0.5666 - val_acc: 0.8070\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3918 - acc: 0.8622 - val_loss: 0.5592 - val_acc: 0.8060\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3903 - acc: 0.8625 - val_loss: 0.5591 - val_acc: 0.7980\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3883 - acc: 0.8627 - val_loss: 0.5603 - val_acc: 0.7990\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3867 - acc: 0.8638 - val_loss: 0.5644 - val_acc: 0.8000\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3847 - acc: 0.8644 - val_loss: 0.5606 - val_acc: 0.8010\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3834 - acc: 0.8644 - val_loss: 0.5700 - val_acc: 0.8010\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3819 - acc: 0.8657 - val_loss: 0.5637 - val_acc: 0.7980\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3802 - acc: 0.8659 - val_loss: 0.5625 - val_acc: 0.7960\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3787 - acc: 0.8662 - val_loss: 0.5633 - val_acc: 0.8000\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3772 - acc: 0.8669 - val_loss: 0.5698 - val_acc: 0.8030\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3755 - acc: 0.8675 - val_loss: 0.5660 - val_acc: 0.7990\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3742 - acc: 0.8674 - val_loss: 0.5648 - val_acc: 0.8050\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3727 - acc: 0.8690 - val_loss: 0.5706 - val_acc: 0.8010\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3712 - acc: 0.8686 - val_loss: 0.5695 - val_acc: 0.7990\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3697 - acc: 0.8696 - val_loss: 0.5794 - val_acc: 0.8060\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.3686 - acc: 0.8697 - val_loss: 0.5678 - val_acc: 0.7960\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.3671 - acc: 0.8706 - val_loss: 0.5740 - val_acc: 0.8070\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3655 - acc: 0.8710 - val_loss: 0.5706 - val_acc: 0.7950\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3643 - acc: 0.8710 - val_loss: 0.5738 - val_acc: 0.8020\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3630 - acc: 0.8723 - val_loss: 0.5716 - val_acc: 0.7980\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.3618 - acc: 0.8723 - val_loss: 0.5769 - val_acc: 0.8030\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3602 - acc: 0.8724 - val_loss: 0.5770 - val_acc: 0.7940\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3590 - acc: 0.8725 - val_loss: 0.5865 - val_acc: 0.8010\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3579 - acc: 0.8735 - val_loss: 0.5832 - val_acc: 0.7980\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3565 - acc: 0.8747 - val_loss: 0.5808 - val_acc: 0.8090\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.3555 - acc: 0.8745 - val_loss: 0.5877 - val_acc: 0.8000\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3545 - acc: 0.8748 - val_loss: 0.5766 - val_acc: 0.7970\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3529 - acc: 0.8745 - val_loss: 0.5815 - val_acc: 0.7960\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3516 - acc: 0.8761 - val_loss: 0.5778 - val_acc: 0.7990\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3505 - acc: 0.8757 - val_loss: 0.5784 - val_acc: 0.7920\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3494 - acc: 0.8763 - val_loss: 0.5782 - val_acc: 0.7960\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3479 - acc: 0.8766 - val_loss: 0.5826 - val_acc: 0.7990\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.3469 - acc: 0.8770 - val_loss: 0.5830 - val_acc: 0.7970\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3457 - acc: 0.8773 - val_loss: 0.5843 - val_acc: 0.7910\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3445 - acc: 0.8778 - val_loss: 0.5859 - val_acc: 0.8000\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3433 - acc: 0.8788 - val_loss: 0.5922 - val_acc: 0.8020\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3421 - acc: 0.8793 - val_loss: 0.5867 - val_acc: 0.7990\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3410 - acc: 0.8791 - val_loss: 0.5865 - val_acc: 0.7930\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.3399 - acc: 0.8797 - val_loss: 0.5958 - val_acc: 0.7980\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3388 - acc: 0.8800 - val_loss: 0.5903 - val_acc: 0.7920\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3380 - acc: 0.8810 - val_loss: 0.5878 - val_acc: 0.7920\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3366 - acc: 0.8802 - val_loss: 0.5954 - val_acc: 0.8050\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3356 - acc: 0.8810 - val_loss: 0.5922 - val_acc: 0.7960\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3344 - acc: 0.8822 - val_loss: 0.5952 - val_acc: 0.7940\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.3334 - acc: 0.8824 - val_loss: 0.5939 - val_acc: 0.7930\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.3322 - acc: 0.8825 - val_loss: 0.5914 - val_acc: 0.7940\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3311 - acc: 0.8833 - val_loss: 0.5936 - val_acc: 0.7950\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3303 - acc: 0.8835 - val_loss: 0.5945 - val_acc: 0.7990\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3290 - acc: 0.8828 - val_loss: 0.6031 - val_acc: 0.8010\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3279 - acc: 0.8843 - val_loss: 0.6059 - val_acc: 0.7970\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3271 - acc: 0.8847 - val_loss: 0.6036 - val_acc: 0.7990\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3256 - acc: 0.8848 - val_loss: 0.5977 - val_acc: 0.7910\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3246 - acc: 0.8860 - val_loss: 0.6011 - val_acc: 0.7950\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3238 - acc: 0.8859 - val_loss: 0.6037 - val_acc: 0.7920\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3229 - acc: 0.8863 - val_loss: 0.6028 - val_acc: 0.7930\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3216 - acc: 0.8870 - val_loss: 0.6087 - val_acc: 0.7950\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3205 - acc: 0.8878 - val_loss: 0.6046 - val_acc: 0.7960\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3196 - acc: 0.8880 - val_loss: 0.6061 - val_acc: 0.7970\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3186 - acc: 0.8881 - val_loss: 0.6158 - val_acc: 0.8020\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.3173 - acc: 0.8887 - val_loss: 0.6031 - val_acc: 0.7940\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3164 - acc: 0.8889 - val_loss: 0.6082 - val_acc: 0.7960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.3154 - acc: 0.8895 - val_loss: 0.6093 - val_acc: 0.7990\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3141 - acc: 0.8896 - val_loss: 0.6194 - val_acc: 0.8020\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.3137 - acc: 0.8891 - val_loss: 0.6109 - val_acc: 0.7920\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3123 - acc: 0.8905 - val_loss: 0.6088 - val_acc: 0.7950\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.3115 - acc: 0.8912 - val_loss: 0.6149 - val_acc: 0.8000\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3106 - acc: 0.8914 - val_loss: 0.6261 - val_acc: 0.7950\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.3094 - acc: 0.8924 - val_loss: 0.6113 - val_acc: 0.7920\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3082 - acc: 0.8930 - val_loss: 0.6199 - val_acc: 0.7940\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.3071 - acc: 0.8927 - val_loss: 0.6241 - val_acc: 0.7960\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3059 - acc: 0.8931 - val_loss: 0.6144 - val_acc: 0.7970\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3048 - acc: 0.8928 - val_loss: 0.6149 - val_acc: 0.7960\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3040 - acc: 0.8938 - val_loss: 0.6153 - val_acc: 0.7980\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.3025 - acc: 0.8943 - val_loss: 0.6172 - val_acc: 0.7940\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.3016 - acc: 0.8949 - val_loss: 0.6265 - val_acc: 0.7900\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.3009 - acc: 0.8956 - val_loss: 0.6271 - val_acc: 0.7950\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.2999 - acc: 0.8954 - val_loss: 0.6218 - val_acc: 0.7980\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.2986 - acc: 0.8969 - val_loss: 0.6307 - val_acc: 0.7970\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.2976 - acc: 0.8962 - val_loss: 0.6227 - val_acc: 0.7920\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.2968 - acc: 0.8964 - val_loss: 0.6395 - val_acc: 0.7970\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.2955 - acc: 0.8966 - val_loss: 0.6291 - val_acc: 0.7910\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.2950 - acc: 0.8973 - val_loss: 0.6308 - val_acc: 0.8040\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.2934 - acc: 0.8977 - val_loss: 0.6276 - val_acc: 0.7960\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2923 - acc: 0.8986 - val_loss: 0.6265 - val_acc: 0.7940\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2914 - acc: 0.8990 - val_loss: 0.6342 - val_acc: 0.7960\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2902 - acc: 0.8987 - val_loss: 0.6430 - val_acc: 0.7930\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2892 - acc: 0.9000 - val_loss: 0.6388 - val_acc: 0.7900\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2882 - acc: 0.8996 - val_loss: 0.6377 - val_acc: 0.7990\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2872 - acc: 0.9000 - val_loss: 0.6344 - val_acc: 0.7980\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2862 - acc: 0.9005 - val_loss: 0.6367 - val_acc: 0.7930\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2851 - acc: 0.9018 - val_loss: 0.6437 - val_acc: 0.7880\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2836 - acc: 0.9022 - val_loss: 0.6361 - val_acc: 0.7970\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2829 - acc: 0.9023 - val_loss: 0.6377 - val_acc: 0.7960\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.2815 - acc: 0.9018 - val_loss: 0.6466 - val_acc: 0.7850\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens, y_train_lb, epochs=150, batch_size=256, validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 32us/step\n",
      "----------\n",
      "Training Loss: 0.276 \n",
      "Training Accuracy: 0.906\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 56us/step\n",
      "----------\n",
      "Test Loss: 0.607 \n",
      "Test Accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.plot(history['acc'])\n",
    "    plt.legend(['val_acc', 'acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "visualize_training_results(baseline_model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=2), ModelCheckpoint(filepath='best_model', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 1.8598 - acc: 0.2445 - val_loss: 1.7376 - val_acc: 0.3340\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.5574 - acc: 0.4631 - val_loss: 1.3592 - val_acc: 0.5670\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 1.1944 - acc: 0.6284 - val_loss: 1.0477 - val_acc: 0.6530\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.9491 - acc: 0.6902 - val_loss: 0.8729 - val_acc: 0.6940\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.8134 - acc: 0.7209 - val_loss: 0.7767 - val_acc: 0.7220\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.7364 - acc: 0.7397 - val_loss: 0.7227 - val_acc: 0.7320\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6877 - acc: 0.7520 - val_loss: 0.6835 - val_acc: 0.7450\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6536 - acc: 0.7633 - val_loss: 0.6604 - val_acc: 0.7480\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6276 - acc: 0.7716 - val_loss: 0.6431 - val_acc: 0.7580\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6070 - acc: 0.7793 - val_loss: 0.6292 - val_acc: 0.7610\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5897 - acc: 0.7848 - val_loss: 0.6166 - val_acc: 0.7640\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5751 - acc: 0.7903 - val_loss: 0.6079 - val_acc: 0.7780\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5625 - acc: 0.7951 - val_loss: 0.5998 - val_acc: 0.7740\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5513 - acc: 0.8003 - val_loss: 0.5970 - val_acc: 0.7690\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5412 - acc: 0.8033 - val_loss: 0.5876 - val_acc: 0.7810\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5321 - acc: 0.8076 - val_loss: 0.5821 - val_acc: 0.7920\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5236 - acc: 0.8114 - val_loss: 0.5836 - val_acc: 0.7840\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5162 - acc: 0.8138 - val_loss: 0.5786 - val_acc: 0.7880\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5091 - acc: 0.8169 - val_loss: 0.5722 - val_acc: 0.7890\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5024 - acc: 0.8197 - val_loss: 0.5703 - val_acc: 0.7960\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4964 - acc: 0.8220 - val_loss: 0.5690 - val_acc: 0.7870\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.4907 - acc: 0.8238 - val_loss: 0.5640 - val_acc: 0.7950\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.4851 - acc: 0.8260 - val_loss: 0.5662 - val_acc: 0.7920\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.4803 - acc: 0.8284 - val_loss: 0.5619 - val_acc: 0.7990\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.4755 - acc: 0.8302 - val_loss: 0.5619 - val_acc: 0.7980\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.4710 - acc: 0.8322 - val_loss: 0.5584 - val_acc: 0.7980\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.4668 - acc: 0.8330 - val_loss: 0.5553 - val_acc: 0.7980\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.4627 - acc: 0.8349 - val_loss: 0.5560 - val_acc: 0.8000\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.4591 - acc: 0.8362 - val_loss: 0.5569 - val_acc: 0.7990\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens, y_train_lb, epochs=150, batch_size=256, callbacks=early_stopping, validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 38us/step\n",
      "Training Loss: 0.462 \n",
      "Training Accuracy: 0.836\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 45us/step\n",
      "Test Loss: 0.564 \n",
      "Test Accuracy: 0.783\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 2.5232 - acc: 0.2354 - val_loss: 2.4130 - val_acc: 0.3320\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 2.2034 - acc: 0.4938 - val_loss: 1.9936 - val_acc: 0.5750\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 1.8050 - acc: 0.6373 - val_loss: 1.6607 - val_acc: 0.6660\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 1.5505 - acc: 0.6934 - val_loss: 1.4789 - val_acc: 0.7060\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.4094 - acc: 0.7207 - val_loss: 1.3777 - val_acc: 0.7220\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.3223 - acc: 0.7369 - val_loss: 1.3103 - val_acc: 0.7320\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.2600 - acc: 0.7506 - val_loss: 1.2599 - val_acc: 0.7470\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.2114 - acc: 0.7608 - val_loss: 1.2214 - val_acc: 0.7480\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.1708 - acc: 0.7694 - val_loss: 1.1842 - val_acc: 0.7630\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 1.1354 - acc: 0.7758 - val_loss: 1.1539 - val_acc: 0.7710\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.1036 - acc: 0.7831 - val_loss: 1.1258 - val_acc: 0.7740\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 1.0751 - acc: 0.7874 - val_loss: 1.1013 - val_acc: 0.7750\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 1.0487 - acc: 0.7921 - val_loss: 1.0792 - val_acc: 0.7750\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.0243 - acc: 0.7972 - val_loss: 1.0610 - val_acc: 0.7770\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.0016 - acc: 0.7999 - val_loss: 1.0406 - val_acc: 0.7780\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.9805 - acc: 0.8027 - val_loss: 1.0231 - val_acc: 0.7760\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.9605 - acc: 0.8070 - val_loss: 1.0055 - val_acc: 0.7790\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.9419 - acc: 0.8093 - val_loss: 0.9845 - val_acc: 0.7920\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.9241 - acc: 0.8120 - val_loss: 0.9699 - val_acc: 0.7950\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.9076 - acc: 0.8144 - val_loss: 0.9610 - val_acc: 0.7920\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.8919 - acc: 0.8163 - val_loss: 0.9427 - val_acc: 0.7900\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8769 - acc: 0.8196 - val_loss: 0.9327 - val_acc: 0.7880\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8626 - acc: 0.8203 - val_loss: 0.9206 - val_acc: 0.7970\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.8492 - acc: 0.8225 - val_loss: 0.9091 - val_acc: 0.7960\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.8364 - acc: 0.8241 - val_loss: 0.8955 - val_acc: 0.7990\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8241 - acc: 0.8261 - val_loss: 0.8896 - val_acc: 0.8020\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8125 - acc: 0.8271 - val_loss: 0.8761 - val_acc: 0.8000\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8015 - acc: 0.8295 - val_loss: 0.8689 - val_acc: 0.7950\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.7910 - acc: 0.8305 - val_loss: 0.8580 - val_acc: 0.8050\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.7808 - acc: 0.8317 - val_loss: 0.8487 - val_acc: 0.8080\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.7714 - acc: 0.8328 - val_loss: 0.8424 - val_acc: 0.8070\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.7620 - acc: 0.8335 - val_loss: 0.8366 - val_acc: 0.8000\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.7533 - acc: 0.8353 - val_loss: 0.8288 - val_acc: 0.8100\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.7450 - acc: 0.8362 - val_loss: 0.8213 - val_acc: 0.8080\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.7370 - acc: 0.8373 - val_loss: 0.8135 - val_acc: 0.8050\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.7293 - acc: 0.8384 - val_loss: 0.8063 - val_acc: 0.8090\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7221 - acc: 0.8390 - val_loss: 0.8024 - val_acc: 0.8080\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.7149 - acc: 0.8405 - val_loss: 0.7939 - val_acc: 0.8100\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.7083 - acc: 0.8412 - val_loss: 0.7888 - val_acc: 0.8060\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.7018 - acc: 0.8417 - val_loss: 0.7893 - val_acc: 0.8080\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6957 - acc: 0.8414 - val_loss: 0.7797 - val_acc: 0.8080\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6897 - acc: 0.8430 - val_loss: 0.7774 - val_acc: 0.8090\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6839 - acc: 0.8440 - val_loss: 0.7701 - val_acc: 0.8110\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.6785 - acc: 0.8439 - val_loss: 0.7664 - val_acc: 0.8050\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6736 - acc: 0.8446 - val_loss: 0.7618 - val_acc: 0.8090\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6684 - acc: 0.8448 - val_loss: 0.7618 - val_acc: 0.8100\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.6637 - acc: 0.8457 - val_loss: 0.7607 - val_acc: 0.8120\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.6591 - acc: 0.8459 - val_loss: 0.7523 - val_acc: 0.8110\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6547 - acc: 0.8466 - val_loss: 0.7536 - val_acc: 0.8090\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6507 - acc: 0.8470 - val_loss: 0.7460 - val_acc: 0.8130\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6464 - acc: 0.8476 - val_loss: 0.7451 - val_acc: 0.8090\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6423 - acc: 0.8479 - val_loss: 0.7396 - val_acc: 0.8150\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6386 - acc: 0.8489 - val_loss: 0.7361 - val_acc: 0.8120\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6350 - acc: 0.8495 - val_loss: 0.7343 - val_acc: 0.8130\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6315 - acc: 0.8491 - val_loss: 0.7333 - val_acc: 0.8150\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6282 - acc: 0.8500 - val_loss: 0.7300 - val_acc: 0.8120\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.6251 - acc: 0.8504 - val_loss: 0.7252 - val_acc: 0.8040\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6218 - acc: 0.8507 - val_loss: 0.7250 - val_acc: 0.8120\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.6187 - acc: 0.8514 - val_loss: 0.7223 - val_acc: 0.8080\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6160 - acc: 0.8507 - val_loss: 0.7221 - val_acc: 0.8140\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6132 - acc: 0.8511 - val_loss: 0.7151 - val_acc: 0.8130\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.6105 - acc: 0.8524 - val_loss: 0.7200 - val_acc: 0.8130\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6082 - acc: 0.8518 - val_loss: 0.7174 - val_acc: 0.8120\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6053 - acc: 0.8525 - val_loss: 0.7141 - val_acc: 0.8140\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.6032 - acc: 0.8525 - val_loss: 0.7119 - val_acc: 0.8170\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6005 - acc: 0.8533 - val_loss: 0.7060 - val_acc: 0.8140\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5986 - acc: 0.8532 - val_loss: 0.7064 - val_acc: 0.8130\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5965 - acc: 0.8537 - val_loss: 0.7034 - val_acc: 0.8140\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5941 - acc: 0.8543 - val_loss: 0.7033 - val_acc: 0.8040\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5925 - acc: 0.8542 - val_loss: 0.7002 - val_acc: 0.8160\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5905 - acc: 0.8541 - val_loss: 0.6993 - val_acc: 0.8170\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5883 - acc: 0.8545 - val_loss: 0.6996 - val_acc: 0.8150\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5865 - acc: 0.8548 - val_loss: 0.7021 - val_acc: 0.8130\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5847 - acc: 0.8553 - val_loss: 0.6987 - val_acc: 0.8160\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5831 - acc: 0.8554 - val_loss: 0.6943 - val_acc: 0.8110\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5815 - acc: 0.8553 - val_loss: 0.6957 - val_acc: 0.8130\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5797 - acc: 0.8551 - val_loss: 0.6932 - val_acc: 0.8140\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5781 - acc: 0.8558 - val_loss: 0.6926 - val_acc: 0.8150\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5765 - acc: 0.8560 - val_loss: 0.6922 - val_acc: 0.8130\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5753 - acc: 0.8559 - val_loss: 0.6898 - val_acc: 0.8130\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5736 - acc: 0.8565 - val_loss: 0.6880 - val_acc: 0.8200\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5724 - acc: 0.8562 - val_loss: 0.6902 - val_acc: 0.8140\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5708 - acc: 0.8569 - val_loss: 0.6860 - val_acc: 0.8100\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5698 - acc: 0.8571 - val_loss: 0.6891 - val_acc: 0.8170\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5684 - acc: 0.8568 - val_loss: 0.6840 - val_acc: 0.8080\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5674 - acc: 0.8576 - val_loss: 0.6851 - val_acc: 0.8150\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5659 - acc: 0.8577 - val_loss: 0.6855 - val_acc: 0.8150\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5648 - acc: 0.8576 - val_loss: 0.6816 - val_acc: 0.8180\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5639 - acc: 0.8577 - val_loss: 0.6831 - val_acc: 0.8100\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5628 - acc: 0.8578 - val_loss: 0.6813 - val_acc: 0.8120\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5616 - acc: 0.8580 - val_loss: 0.6875 - val_acc: 0.8090\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5607 - acc: 0.8584 - val_loss: 0.6821 - val_acc: 0.8100\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5598 - acc: 0.8578 - val_loss: 0.6831 - val_acc: 0.8110\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5587 - acc: 0.8581 - val_loss: 0.6807 - val_acc: 0.8150\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5576 - acc: 0.8586 - val_loss: 0.6785 - val_acc: 0.8080\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5567 - acc: 0.8587 - val_loss: 0.6777 - val_acc: 0.8090\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5559 - acc: 0.8578 - val_loss: 0.6752 - val_acc: 0.8090\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5551 - acc: 0.8590 - val_loss: 0.6764 - val_acc: 0.8090\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5539 - acc: 0.8591 - val_loss: 0.6744 - val_acc: 0.8110\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5533 - acc: 0.8592 - val_loss: 0.6773 - val_acc: 0.8130\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5520 - acc: 0.8588 - val_loss: 0.6792 - val_acc: 0.8140\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5513 - acc: 0.8590 - val_loss: 0.6736 - val_acc: 0.8110\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5505 - acc: 0.8594 - val_loss: 0.6738 - val_acc: 0.8120\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5499 - acc: 0.8593 - val_loss: 0.6733 - val_acc: 0.8080\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5491 - acc: 0.8590 - val_loss: 0.6745 - val_acc: 0.8160\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5482 - acc: 0.8601 - val_loss: 0.6749 - val_acc: 0.8100\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5476 - acc: 0.8600 - val_loss: 0.6757 - val_acc: 0.8090\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5470 - acc: 0.8607 - val_loss: 0.6734 - val_acc: 0.8130\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5458 - acc: 0.8607 - val_loss: 0.6734 - val_acc: 0.8120\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5454 - acc: 0.8599 - val_loss: 0.6735 - val_acc: 0.8150\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5450 - acc: 0.8605 - val_loss: 0.6702 - val_acc: 0.8120\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5442 - acc: 0.8606 - val_loss: 0.6797 - val_acc: 0.8060\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5436 - acc: 0.8603 - val_loss: 0.6733 - val_acc: 0.8160\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5431 - acc: 0.8602 - val_loss: 0.6791 - val_acc: 0.8080\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5423 - acc: 0.8609 - val_loss: 0.6756 - val_acc: 0.8040\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5413 - acc: 0.8610 - val_loss: 0.6729 - val_acc: 0.8020\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5409 - acc: 0.8612 - val_loss: 0.6681 - val_acc: 0.8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5404 - acc: 0.8610 - val_loss: 0.6715 - val_acc: 0.8160\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5398 - acc: 0.8616 - val_loss: 0.6667 - val_acc: 0.8110\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5392 - acc: 0.8618 - val_loss: 0.6710 - val_acc: 0.8120\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5386 - acc: 0.8613 - val_loss: 0.6738 - val_acc: 0.8050\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5379 - acc: 0.8604 - val_loss: 0.6715 - val_acc: 0.8180\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5375 - acc: 0.8611 - val_loss: 0.6701 - val_acc: 0.8100\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5370 - acc: 0.8617 - val_loss: 0.6704 - val_acc: 0.8060\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5362 - acc: 0.8617 - val_loss: 0.6670 - val_acc: 0.8100\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5359 - acc: 0.8618 - val_loss: 0.6710 - val_acc: 0.8160\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5357 - acc: 0.8614 - val_loss: 0.6637 - val_acc: 0.8090\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5348 - acc: 0.8614 - val_loss: 0.6701 - val_acc: 0.8050\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5343 - acc: 0.8619 - val_loss: 0.6671 - val_acc: 0.8110\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - ETA: 0s - loss: 0.5346 - acc: 0.861 - 1s 26us/step - loss: 0.5339 - acc: 0.8619 - val_loss: 0.6693 - val_acc: 0.8140\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5334 - acc: 0.8618 - val_loss: 0.6666 - val_acc: 0.8140\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5327 - acc: 0.8624 - val_loss: 0.6685 - val_acc: 0.8110\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5324 - acc: 0.8620 - val_loss: 0.6656 - val_acc: 0.8090\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5318 - acc: 0.8629 - val_loss: 0.6670 - val_acc: 0.8040\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5314 - acc: 0.8624 - val_loss: 0.6680 - val_acc: 0.8090\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5308 - acc: 0.8625 - val_loss: 0.6660 - val_acc: 0.8050\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5307 - acc: 0.8622 - val_loss: 0.6696 - val_acc: 0.8080\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5298 - acc: 0.8633 - val_loss: 0.6613 - val_acc: 0.8020\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5297 - acc: 0.8615 - val_loss: 0.6706 - val_acc: 0.8050\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5292 - acc: 0.8621 - val_loss: 0.6624 - val_acc: 0.8090\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5289 - acc: 0.8625 - val_loss: 0.6679 - val_acc: 0.8060\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5285 - acc: 0.8630 - val_loss: 0.6612 - val_acc: 0.8090\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5278 - acc: 0.8626 - val_loss: 0.6610 - val_acc: 0.8060\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5274 - acc: 0.8618 - val_loss: 0.6637 - val_acc: 0.8090\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5270 - acc: 0.8639 - val_loss: 0.6632 - val_acc: 0.8060\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5267 - acc: 0.8636 - val_loss: 0.6646 - val_acc: 0.8100\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5264 - acc: 0.8633 - val_loss: 0.6651 - val_acc: 0.8060\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5258 - acc: 0.8636 - val_loss: 0.6647 - val_acc: 0.8070\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5255 - acc: 0.8635 - val_loss: 0.6620 - val_acc: 0.8090\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5250 - acc: 0.8632 - val_loss: 0.6617 - val_acc: 0.8110\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,)))\n",
    "L2_model.add(layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Add another hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['acc'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 2.4835 - acc: 0.2386 - val_loss: 2.3480 - val_acc: 0.3320\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 2.1395 - acc: 0.4650 - val_loss: 1.9472 - val_acc: 0.5770\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.7765 - acc: 0.6313 - val_loss: 1.6476 - val_acc: 0.6700\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 1.5457 - acc: 0.6900 - val_loss: 1.4739 - val_acc: 0.6870\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 1.4096 - acc: 0.7187 - val_loss: 1.3768 - val_acc: 0.7010\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 1.3218 - acc: 0.7367 - val_loss: 1.3054 - val_acc: 0.7280\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 1.2588 - acc: 0.7493 - val_loss: 1.2577 - val_acc: 0.7310\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.2095 - acc: 0.7586 - val_loss: 1.2135 - val_acc: 0.7460\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.1685 - acc: 0.7674 - val_loss: 1.1796 - val_acc: 0.7550\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.1333 - acc: 0.7731 - val_loss: 1.1457 - val_acc: 0.7680\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 1.1019 - acc: 0.7783 - val_loss: 1.1223 - val_acc: 0.7660\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 1.0734 - acc: 0.7835 - val_loss: 1.0976 - val_acc: 0.7680\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 1.0474 - acc: 0.7876 - val_loss: 1.0789 - val_acc: 0.7690\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 1.0233 - acc: 0.7918 - val_loss: 1.0532 - val_acc: 0.7760\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 1.0012 - acc: 0.7957 - val_loss: 1.0343 - val_acc: 0.7830\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.9803 - acc: 0.7990 - val_loss: 1.0166 - val_acc: 0.7800\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.9608 - acc: 0.8024 - val_loss: 0.9991 - val_acc: 0.7770\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.9424 - acc: 0.8048 - val_loss: 0.9819 - val_acc: 0.7880\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.9249 - acc: 0.8078 - val_loss: 0.9676 - val_acc: 0.7920\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.9084 - acc: 0.8098 - val_loss: 0.9555 - val_acc: 0.7920\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8929 - acc: 0.8122 - val_loss: 0.9391 - val_acc: 0.7870\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.8782 - acc: 0.8141 - val_loss: 0.9313 - val_acc: 0.7910\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.8642 - acc: 0.8167 - val_loss: 0.9184 - val_acc: 0.7920\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.8507 - acc: 0.8180 - val_loss: 0.9086 - val_acc: 0.7960\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.8380 - acc: 0.8206 - val_loss: 0.8969 - val_acc: 0.7970\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.8258 - acc: 0.8211 - val_loss: 0.8842 - val_acc: 0.7960\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.8144 - acc: 0.8237 - val_loss: 0.8744 - val_acc: 0.7940\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.8031 - acc: 0.8257 - val_loss: 0.8712 - val_acc: 0.7940\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.7926 - acc: 0.8269 - val_loss: 0.8569 - val_acc: 0.7950\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7826 - acc: 0.8281 - val_loss: 0.8496 - val_acc: 0.7970\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7729 - acc: 0.8297 - val_loss: 0.8404 - val_acc: 0.8010\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7638 - acc: 0.8307 - val_loss: 0.8387 - val_acc: 0.7970\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7549 - acc: 0.8318 - val_loss: 0.8263 - val_acc: 0.8020\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7466 - acc: 0.8328 - val_loss: 0.8174 - val_acc: 0.7990\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7385 - acc: 0.8342 - val_loss: 0.8173 - val_acc: 0.8020\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7308 - acc: 0.8354 - val_loss: 0.8073 - val_acc: 0.8000\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.7235 - acc: 0.8361 - val_loss: 0.8014 - val_acc: 0.8040\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.7165 - acc: 0.8375 - val_loss: 0.7945 - val_acc: 0.8050\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.7098 - acc: 0.8388 - val_loss: 0.7920 - val_acc: 0.8000\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.7033 - acc: 0.8383 - val_loss: 0.7862 - val_acc: 0.8080\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6970 - acc: 0.8396 - val_loss: 0.7792 - val_acc: 0.8090\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6909 - acc: 0.8406 - val_loss: 0.7744 - val_acc: 0.8030\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.6857 - acc: 0.8417 - val_loss: 0.7737 - val_acc: 0.8050\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6799 - acc: 0.8417 - val_loss: 0.7649 - val_acc: 0.8100\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6749 - acc: 0.8429 - val_loss: 0.7644 - val_acc: 0.8070\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.6699 - acc: 0.8429 - val_loss: 0.7563 - val_acc: 0.8070\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6648 - acc: 0.8450 - val_loss: 0.7559 - val_acc: 0.8080\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6602 - acc: 0.8449 - val_loss: 0.7502 - val_acc: 0.8060\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6558 - acc: 0.8453 - val_loss: 0.7459 - val_acc: 0.8090\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.6515 - acc: 0.8464 - val_loss: 0.7442 - val_acc: 0.8100\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.6474 - acc: 0.8464 - val_loss: 0.7417 - val_acc: 0.8120\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6435 - acc: 0.8471 - val_loss: 0.7389 - val_acc: 0.8060\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6397 - acc: 0.8475 - val_loss: 0.7372 - val_acc: 0.8070\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6360 - acc: 0.8479 - val_loss: 0.7313 - val_acc: 0.8040\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6326 - acc: 0.8487 - val_loss: 0.7288 - val_acc: 0.8120\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6293 - acc: 0.8491 - val_loss: 0.7276 - val_acc: 0.8140\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6260 - acc: 0.8490 - val_loss: 0.7226 - val_acc: 0.8110\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6229 - acc: 0.8500 - val_loss: 0.7324 - val_acc: 0.7970\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.6200 - acc: 0.8501 - val_loss: 0.7198 - val_acc: 0.8100\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.6170 - acc: 0.8514 - val_loss: 0.7212 - val_acc: 0.8100\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6145 - acc: 0.8510 - val_loss: 0.7245 - val_acc: 0.7960\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.6115 - acc: 0.8510 - val_loss: 0.7193 - val_acc: 0.8040\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.6088 - acc: 0.8511 - val_loss: 0.7131 - val_acc: 0.8080\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.6064 - acc: 0.8529 - val_loss: 0.7109 - val_acc: 0.8080\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6042 - acc: 0.8523 - val_loss: 0.7106 - val_acc: 0.8030\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.6015 - acc: 0.8526 - val_loss: 0.7066 - val_acc: 0.8110\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5993 - acc: 0.8532 - val_loss: 0.7073 - val_acc: 0.8100\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5974 - acc: 0.8538 - val_loss: 0.7037 - val_acc: 0.8130\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5948 - acc: 0.8542 - val_loss: 0.7024 - val_acc: 0.8050\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5932 - acc: 0.8534 - val_loss: 0.7020 - val_acc: 0.8060\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5912 - acc: 0.8542 - val_loss: 0.6986 - val_acc: 0.8070\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5892 - acc: 0.8553 - val_loss: 0.7001 - val_acc: 0.8050\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5872 - acc: 0.8544 - val_loss: 0.6981 - val_acc: 0.8040\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5857 - acc: 0.8543 - val_loss: 0.6949 - val_acc: 0.8090\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5840 - acc: 0.8553 - val_loss: 0.6947 - val_acc: 0.8090\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5822 - acc: 0.8562 - val_loss: 0.6965 - val_acc: 0.8040\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5807 - acc: 0.8563 - val_loss: 0.6921 - val_acc: 0.8080\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5791 - acc: 0.8552 - val_loss: 0.6906 - val_acc: 0.8040\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5773 - acc: 0.8563 - val_loss: 0.6902 - val_acc: 0.8020\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5762 - acc: 0.8561 - val_loss: 0.6944 - val_acc: 0.8000\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5745 - acc: 0.8562 - val_loss: 0.6884 - val_acc: 0.8010\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5733 - acc: 0.8564 - val_loss: 0.6865 - val_acc: 0.8080\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5720 - acc: 0.8556 - val_loss: 0.6920 - val_acc: 0.8030\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5706 - acc: 0.8567 - val_loss: 0.6886 - val_acc: 0.8090\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5690 - acc: 0.8573 - val_loss: 0.6905 - val_acc: 0.8100\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5683 - acc: 0.8567 - val_loss: 0.6855 - val_acc: 0.8060\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5670 - acc: 0.8566 - val_loss: 0.6856 - val_acc: 0.8040\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5656 - acc: 0.8573 - val_loss: 0.6813 - val_acc: 0.8100\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5647 - acc: 0.8566 - val_loss: 0.6799 - val_acc: 0.8070\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5635 - acc: 0.8578 - val_loss: 0.6797 - val_acc: 0.8050\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5623 - acc: 0.8580 - val_loss: 0.6788 - val_acc: 0.8000\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5617 - acc: 0.8577 - val_loss: 0.6796 - val_acc: 0.8030\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5604 - acc: 0.8586 - val_loss: 0.6824 - val_acc: 0.8070\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5593 - acc: 0.8589 - val_loss: 0.6807 - val_acc: 0.8030\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5586 - acc: 0.8582 - val_loss: 0.6790 - val_acc: 0.8100\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5575 - acc: 0.8581 - val_loss: 0.6786 - val_acc: 0.8040\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5567 - acc: 0.8588 - val_loss: 0.6760 - val_acc: 0.8080\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5557 - acc: 0.8587 - val_loss: 0.6824 - val_acc: 0.7960\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5551 - acc: 0.8588 - val_loss: 0.6796 - val_acc: 0.8100\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5539 - acc: 0.8589 - val_loss: 0.6775 - val_acc: 0.8050\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5532 - acc: 0.8592 - val_loss: 0.6777 - val_acc: 0.8050\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5524 - acc: 0.8595 - val_loss: 0.6795 - val_acc: 0.8030\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5513 - acc: 0.8593 - val_loss: 0.6728 - val_acc: 0.8030\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 1s 24us/step - loss: 0.5508 - acc: 0.8594 - val_loss: 0.6764 - val_acc: 0.8050\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5498 - acc: 0.8598 - val_loss: 0.6733 - val_acc: 0.8050\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5492 - acc: 0.8601 - val_loss: 0.6730 - val_acc: 0.8050\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5484 - acc: 0.8601 - val_loss: 0.6723 - val_acc: 0.8010\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5475 - acc: 0.8604 - val_loss: 0.6749 - val_acc: 0.8010\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5468 - acc: 0.8606 - val_loss: 0.6722 - val_acc: 0.8070\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5463 - acc: 0.8595 - val_loss: 0.6733 - val_acc: 0.8070\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5458 - acc: 0.8613 - val_loss: 0.6743 - val_acc: 0.8060\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5452 - acc: 0.8599 - val_loss: 0.6703 - val_acc: 0.8060\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5442 - acc: 0.8603 - val_loss: 0.6701 - val_acc: 0.7990\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5436 - acc: 0.8602 - val_loss: 0.6720 - val_acc: 0.8060\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.5432 - acc: 0.8607 - val_loss: 0.6720 - val_acc: 0.8030\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5421 - acc: 0.8610 - val_loss: 0.6800 - val_acc: 0.8050\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5420 - acc: 0.8609 - val_loss: 0.6712 - val_acc: 0.8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5413 - acc: 0.8603 - val_loss: 0.6762 - val_acc: 0.8050\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5406 - acc: 0.8606 - val_loss: 0.6670 - val_acc: 0.8010\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5399 - acc: 0.8615 - val_loss: 0.6700 - val_acc: 0.8010\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5394 - acc: 0.8610 - val_loss: 0.6704 - val_acc: 0.8030\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5388 - acc: 0.8615 - val_loss: 0.6685 - val_acc: 0.8040\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5385 - acc: 0.8613 - val_loss: 0.6699 - val_acc: 0.8080\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5379 - acc: 0.8617 - val_loss: 0.6687 - val_acc: 0.7990\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5373 - acc: 0.8617 - val_loss: 0.6750 - val_acc: 0.7990\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5367 - acc: 0.8614 - val_loss: 0.6663 - val_acc: 0.8040\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5363 - acc: 0.8616 - val_loss: 0.6742 - val_acc: 0.8020\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5359 - acc: 0.8613 - val_loss: 0.6686 - val_acc: 0.8100\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5354 - acc: 0.8611 - val_loss: 0.6741 - val_acc: 0.8050\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5349 - acc: 0.8623 - val_loss: 0.6642 - val_acc: 0.8030\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5342 - acc: 0.8619 - val_loss: 0.6644 - val_acc: 0.7990\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5337 - acc: 0.8622 - val_loss: 0.6693 - val_acc: 0.8080\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5329 - acc: 0.8628 - val_loss: 0.6720 - val_acc: 0.8020\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5330 - acc: 0.8614 - val_loss: 0.6692 - val_acc: 0.8040\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5324 - acc: 0.8623 - val_loss: 0.6726 - val_acc: 0.8050\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5319 - acc: 0.8629 - val_loss: 0.6652 - val_acc: 0.8020\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 2s 29us/step - loss: 0.5316 - acc: 0.8620 - val_loss: 0.6658 - val_acc: 0.8040\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 2s 26us/step - loss: 0.5311 - acc: 0.8618 - val_loss: 0.6649 - val_acc: 0.8090\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5306 - acc: 0.8622 - val_loss: 0.6629 - val_acc: 0.8040\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5304 - acc: 0.8632 - val_loss: 0.6650 - val_acc: 0.7980\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5297 - acc: 0.8621 - val_loss: 0.6656 - val_acc: 0.8070\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5293 - acc: 0.8629 - val_loss: 0.6619 - val_acc: 0.8000\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5293 - acc: 0.8621 - val_loss: 0.6637 - val_acc: 0.8010\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5285 - acc: 0.8628 - val_loss: 0.6621 - val_acc: 0.8000\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 1s 26us/step - loss: 0.5280 - acc: 0.8634 - val_loss: 0.6614 - val_acc: 0.8040\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5274 - acc: 0.8630 - val_loss: 0.6771 - val_acc: 0.8110\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5272 - acc: 0.8625 - val_loss: 0.6623 - val_acc: 0.8090\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 1s 25us/step - loss: 0.5266 - acc: 0.8637 - val_loss: 0.6625 - val_acc: 0.8050\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 2s 27us/step - loss: 0.5266 - acc: 0.8631 - val_loss: 0.6624 - val_acc: 0.8120\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 2s 28us/step - loss: 0.5262 - acc: 0.8633 - val_loss: 0.6633 - val_acc: 0.8030\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,)))\n",
    "L1_model.add(layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "\n",
    "# Add a hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 1.9332 - acc: 0.1788 - val_loss: 1.8787 - val_acc: 0.2260\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 1.8600 - acc: 0.2433 - val_loss: 1.7786 - val_acc: 0.3040\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 1.7620 - acc: 0.3022 - val_loss: 1.6002 - val_acc: 0.4530\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 1.6296 - acc: 0.3681 - val_loss: 1.4025 - val_acc: 0.5280\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 1.5098 - acc: 0.4190 - val_loss: 1.2412 - val_acc: 0.5870\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 1.4023 - acc: 0.4670 - val_loss: 1.1164 - val_acc: 0.6410\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 1.3205 - acc: 0.5023 - val_loss: 1.0234 - val_acc: 0.6740\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 1.2518 - acc: 0.5293 - val_loss: 0.9485 - val_acc: 0.7050\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.1899 - acc: 0.5528 - val_loss: 0.8891 - val_acc: 0.7170\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.1418 - acc: 0.5720 - val_loss: 0.8446 - val_acc: 0.7290\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.1023 - acc: 0.5905 - val_loss: 0.8029 - val_acc: 0.7370\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.0683 - acc: 0.6023 - val_loss: 0.7764 - val_acc: 0.7400\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.0368 - acc: 0.6161 - val_loss: 0.7488 - val_acc: 0.7420\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.0108 - acc: 0.6275 - val_loss: 0.7283 - val_acc: 0.7500\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9928 - acc: 0.6326 - val_loss: 0.7104 - val_acc: 0.7480\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9740 - acc: 0.6413 - val_loss: 0.6974 - val_acc: 0.7500\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9531 - acc: 0.6490 - val_loss: 0.6805 - val_acc: 0.7540\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9385 - acc: 0.6534 - val_loss: 0.6714 - val_acc: 0.7510\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.9230 - acc: 0.6595 - val_loss: 0.6628 - val_acc: 0.7520\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.9145 - acc: 0.6630 - val_loss: 0.6550 - val_acc: 0.7540\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9017 - acc: 0.6670 - val_loss: 0.6466 - val_acc: 0.7540\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8881 - acc: 0.6761 - val_loss: 0.6382 - val_acc: 0.7570\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8825 - acc: 0.6759 - val_loss: 0.6332 - val_acc: 0.7580\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8720 - acc: 0.6806 - val_loss: 0.6267 - val_acc: 0.7560\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8585 - acc: 0.6854 - val_loss: 0.6226 - val_acc: 0.7540\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8511 - acc: 0.6879 - val_loss: 0.6191 - val_acc: 0.7600\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8427 - acc: 0.6901 - val_loss: 0.6120 - val_acc: 0.7580\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8391 - acc: 0.6910 - val_loss: 0.6119 - val_acc: 0.7570\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8322 - acc: 0.6935 - val_loss: 0.6083 - val_acc: 0.7550\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8230 - acc: 0.6974 - val_loss: 0.6011 - val_acc: 0.7630\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8204 - acc: 0.6961 - val_loss: 0.6002 - val_acc: 0.7630\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8084 - acc: 0.7006 - val_loss: 0.5949 - val_acc: 0.7600\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8047 - acc: 0.7025 - val_loss: 0.5916 - val_acc: 0.7650\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.7993 - acc: 0.7050 - val_loss: 0.5904 - val_acc: 0.7620\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.7989 - acc: 0.7062 - val_loss: 0.5882 - val_acc: 0.7620\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.7887 - acc: 0.7081 - val_loss: 0.5844 - val_acc: 0.7640\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.7892 - acc: 0.7086 - val_loss: 0.5846 - val_acc: 0.7630\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.7835 - acc: 0.7114 - val_loss: 0.5826 - val_acc: 0.7660\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.7820 - acc: 0.7141 - val_loss: 0.5806 - val_acc: 0.7660\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7769 - acc: 0.7124 - val_loss: 0.5774 - val_acc: 0.7650\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7742 - acc: 0.7144 - val_loss: 0.5767 - val_acc: 0.7640\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7648 - acc: 0.7179 - val_loss: 0.5752 - val_acc: 0.7690\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.7636 - acc: 0.7198 - val_loss: 0.5767 - val_acc: 0.7660\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.7630 - acc: 0.7163 - val_loss: 0.5748 - val_acc: 0.7710\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.7548 - acc: 0.7214 - val_loss: 0.5726 - val_acc: 0.7670\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.7500 - acc: 0.7213 - val_loss: 0.5703 - val_acc: 0.7680\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7451 - acc: 0.7250 - val_loss: 0.5701 - val_acc: 0.7700\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7535 - acc: 0.7230 - val_loss: 0.5705 - val_acc: 0.7710\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7470 - acc: 0.7237 - val_loss: 0.5668 - val_acc: 0.7670\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7355 - acc: 0.7287 - val_loss: 0.5684 - val_acc: 0.7730\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.7342 - acc: 0.7282 - val_loss: 0.5667 - val_acc: 0.7720\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7418 - acc: 0.7267 - val_loss: 0.5652 - val_acc: 0.7720\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.7404 - acc: 0.7279 - val_loss: 0.5653 - val_acc: 0.7750\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7391 - acc: 0.7289 - val_loss: 0.5649 - val_acc: 0.7760\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7321 - acc: 0.7309 - val_loss: 0.5640 - val_acc: 0.7740\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7197 - acc: 0.7337 - val_loss: 0.5618 - val_acc: 0.7730\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7228 - acc: 0.7320 - val_loss: 0.5617 - val_acc: 0.7790\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.7237 - acc: 0.7348 - val_loss: 0.5611 - val_acc: 0.7730\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.7181 - acc: 0.7336 - val_loss: 0.5589 - val_acc: 0.7750\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.7175 - acc: 0.7354 - val_loss: 0.5601 - val_acc: 0.7770\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7140 - acc: 0.7394 - val_loss: 0.5573 - val_acc: 0.7740\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7150 - acc: 0.7353 - val_loss: 0.5602 - val_acc: 0.7720\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7105 - acc: 0.7378 - val_loss: 0.5573 - val_acc: 0.7750\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7099 - acc: 0.7384 - val_loss: 0.5558 - val_acc: 0.7750\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.7096 - acc: 0.7385 - val_loss: 0.5552 - val_acc: 0.7730\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.7082 - acc: 0.7373 - val_loss: 0.5578 - val_acc: 0.7770\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.7033 - acc: 0.7412 - val_loss: 0.5552 - val_acc: 0.7790\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.7022 - acc: 0.7413 - val_loss: 0.5562 - val_acc: 0.7820\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6999 - acc: 0.7410 - val_loss: 0.5557 - val_acc: 0.7800\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.7007 - acc: 0.7421 - val_loss: 0.5540 - val_acc: 0.7750\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7002 - acc: 0.7416 - val_loss: 0.5528 - val_acc: 0.7740\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6973 - acc: 0.7430 - val_loss: 0.5518 - val_acc: 0.7800\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6953 - acc: 0.7420 - val_loss: 0.5532 - val_acc: 0.7790\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6915 - acc: 0.7449 - val_loss: 0.5526 - val_acc: 0.7770\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6894 - acc: 0.7463 - val_loss: 0.5500 - val_acc: 0.7810\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6892 - acc: 0.7470 - val_loss: 0.5511 - val_acc: 0.7880\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6855 - acc: 0.7471 - val_loss: 0.5506 - val_acc: 0.7840\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6884 - acc: 0.7468 - val_loss: 0.5502 - val_acc: 0.7840\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.6845 - acc: 0.7483 - val_loss: 0.5481 - val_acc: 0.7830\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.6817 - acc: 0.7511 - val_loss: 0.5480 - val_acc: 0.7880\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.6840 - acc: 0.7474 - val_loss: 0.5474 - val_acc: 0.7880\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6789 - acc: 0.7511 - val_loss: 0.5478 - val_acc: 0.7760\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6765 - acc: 0.7507 - val_loss: 0.5454 - val_acc: 0.7830\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6823 - acc: 0.7491 - val_loss: 0.5446 - val_acc: 0.7890\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6781 - acc: 0.7501 - val_loss: 0.5471 - val_acc: 0.7810\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6797 - acc: 0.7522 - val_loss: 0.5461 - val_acc: 0.7850\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6725 - acc: 0.7507 - val_loss: 0.5453 - val_acc: 0.7800\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6737 - acc: 0.7521 - val_loss: 0.5451 - val_acc: 0.7880\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6707 - acc: 0.7547 - val_loss: 0.5462 - val_acc: 0.7950\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6718 - acc: 0.7528 - val_loss: 0.5464 - val_acc: 0.7870\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6681 - acc: 0.7539 - val_loss: 0.5445 - val_acc: 0.7900\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6658 - acc: 0.7550 - val_loss: 0.5450 - val_acc: 0.7880\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6625 - acc: 0.7552 - val_loss: 0.5446 - val_acc: 0.7880\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6666 - acc: 0.7555 - val_loss: 0.5433 - val_acc: 0.7870\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.6626 - acc: 0.7556 - val_loss: 0.5431 - val_acc: 0.7830\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6616 - acc: 0.7564 - val_loss: 0.5413 - val_acc: 0.7910\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.6673 - acc: 0.7554 - val_loss: 0.5404 - val_acc: 0.7910\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6616 - acc: 0.7596 - val_loss: 0.5421 - val_acc: 0.7950\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6624 - acc: 0.7572 - val_loss: 0.5406 - val_acc: 0.7910\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6583 - acc: 0.7580 - val_loss: 0.5426 - val_acc: 0.7880\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6596 - acc: 0.7579 - val_loss: 0.5418 - val_acc: 0.7930\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6608 - acc: 0.7581 - val_loss: 0.5400 - val_acc: 0.7940\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6615 - acc: 0.7584 - val_loss: 0.5414 - val_acc: 0.7930\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6574 - acc: 0.7593 - val_loss: 0.5393 - val_acc: 0.7940\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6542 - acc: 0.7580 - val_loss: 0.5377 - val_acc: 0.7930\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.6571 - acc: 0.7586 - val_loss: 0.5387 - val_acc: 0.7940\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6513 - acc: 0.7630 - val_loss: 0.5401 - val_acc: 0.7930\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6503 - acc: 0.7636 - val_loss: 0.5375 - val_acc: 0.7940\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6480 - acc: 0.7624 - val_loss: 0.5385 - val_acc: 0.7960\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6488 - acc: 0.7621 - val_loss: 0.5392 - val_acc: 0.7940\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6510 - acc: 0.7632 - val_loss: 0.5386 - val_acc: 0.7980\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6451 - acc: 0.7646 - val_loss: 0.5372 - val_acc: 0.7980\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6478 - acc: 0.7646 - val_loss: 0.5367 - val_acc: 0.7940\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.6430 - acc: 0.7647 - val_loss: 0.5377 - val_acc: 0.7940\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.6466 - acc: 0.7649 - val_loss: 0.5357 - val_acc: 0.7940\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6481 - acc: 0.7652 - val_loss: 0.5375 - val_acc: 0.7920\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.6416 - acc: 0.7647 - val_loss: 0.5349 - val_acc: 0.8010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6463 - acc: 0.7644 - val_loss: 0.5340 - val_acc: 0.7980\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6374 - acc: 0.7660 - val_loss: 0.5338 - val_acc: 0.8010\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6366 - acc: 0.7675 - val_loss: 0.5324 - val_acc: 0.7990\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.6430 - acc: 0.7677 - val_loss: 0.5334 - val_acc: 0.8010\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6411 - acc: 0.7675 - val_loss: 0.5329 - val_acc: 0.8000\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6375 - acc: 0.7668 - val_loss: 0.5315 - val_acc: 0.8000\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.6375 - acc: 0.7688 - val_loss: 0.5322 - val_acc: 0.8040\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.6334 - acc: 0.7709 - val_loss: 0.5302 - val_acc: 0.8010\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6333 - acc: 0.7719 - val_loss: 0.5326 - val_acc: 0.8030\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6342 - acc: 0.7678 - val_loss: 0.5321 - val_acc: 0.8000\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6385 - acc: 0.7673 - val_loss: 0.5335 - val_acc: 0.8020\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6341 - acc: 0.7694 - val_loss: 0.5336 - val_acc: 0.8050\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6395 - acc: 0.7669 - val_loss: 0.5337 - val_acc: 0.7990\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6371 - acc: 0.7667 - val_loss: 0.5354 - val_acc: 0.8000\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6325 - acc: 0.7686 - val_loss: 0.5362 - val_acc: 0.7990\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6281 - acc: 0.7718 - val_loss: 0.5337 - val_acc: 0.8000\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6278 - acc: 0.7715 - val_loss: 0.5328 - val_acc: 0.7990\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6306 - acc: 0.7713 - val_loss: 0.5339 - val_acc: 0.8000\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6285 - acc: 0.7721 - val_loss: 0.5327 - val_acc: 0.7970\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6251 - acc: 0.7728 - val_loss: 0.5327 - val_acc: 0.7970\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6270 - acc: 0.7707 - val_loss: 0.5337 - val_acc: 0.8020\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6211 - acc: 0.7730 - val_loss: 0.5320 - val_acc: 0.8030\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6226 - acc: 0.7756 - val_loss: 0.5304 - val_acc: 0.8040\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6223 - acc: 0.7747 - val_loss: 0.5292 - val_acc: 0.8030\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6275 - acc: 0.7726 - val_loss: 0.5312 - val_acc: 0.8050\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6260 - acc: 0.7735 - val_loss: 0.5297 - val_acc: 0.8010\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6248 - acc: 0.7735 - val_loss: 0.5315 - val_acc: 0.8010\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6239 - acc: 0.7726 - val_loss: 0.5305 - val_acc: 0.8040\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6249 - acc: 0.7733 - val_loss: 0.5297 - val_acc: 0.8020\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6203 - acc: 0.7753 - val_loss: 0.5306 - val_acc: 0.8030\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6190 - acc: 0.7749 - val_loss: 0.5301 - val_acc: 0.8060\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6196 - acc: 0.7759 - val_loss: 0.5300 - val_acc: 0.7970\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6127 - acc: 0.7771 - val_loss: 0.5300 - val_acc: 0.8030\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(50, activation='relu'))\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 53us/step\n",
      "Training Loss: 0.397 \n",
      "Training Accuracy: 0.861\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 77us/step\n",
      "Test Loss: 0.495 \n",
      "Test Accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 3s 62us/step - loss: 1.8703 - acc: 0.2503 - val_loss: 1.7703 - val_acc: 0.3702\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.6081 - acc: 0.4519 - val_loss: 1.4529 - val_acc: 0.5202\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.2849 - acc: 0.5874 - val_loss: 1.1700 - val_acc: 0.6315\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 1.0444 - acc: 0.6680 - val_loss: 0.9865 - val_acc: 0.6758\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.8928 - acc: 0.7031 - val_loss: 0.8730 - val_acc: 0.7062\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.7985 - acc: 0.7226 - val_loss: 0.8010 - val_acc: 0.7205\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.7377 - acc: 0.7352 - val_loss: 0.7560 - val_acc: 0.7277\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.6961 - acc: 0.7454 - val_loss: 0.7243 - val_acc: 0.7358\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.6657 - acc: 0.7524 - val_loss: 0.6965 - val_acc: 0.7382\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.6423 - acc: 0.7591 - val_loss: 0.6802 - val_acc: 0.7408\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.6230 - acc: 0.7649 - val_loss: 0.6623 - val_acc: 0.7475\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.6069 - acc: 0.7706 - val_loss: 0.6516 - val_acc: 0.7515\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.5931 - acc: 0.7748 - val_loss: 0.6394 - val_acc: 0.7545\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.5809 - acc: 0.7796 - val_loss: 0.6310 - val_acc: 0.7602\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.5700 - acc: 0.7836 - val_loss: 0.6241 - val_acc: 0.7630\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5604 - acc: 0.7885 - val_loss: 0.6140 - val_acc: 0.7657\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.5516 - acc: 0.7925 - val_loss: 0.6112 - val_acc: 0.7605\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.5434 - acc: 0.7961 - val_loss: 0.6096 - val_acc: 0.7713\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.5359 - acc: 0.7986 - val_loss: 0.6006 - val_acc: 0.7735\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.5290 - acc: 0.8024 - val_loss: 0.5925 - val_acc: 0.7757\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.5225 - acc: 0.8057 - val_loss: 0.5870 - val_acc: 0.7775\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.5163 - acc: 0.8079 - val_loss: 0.5848 - val_acc: 0.7798\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.5103 - acc: 0.8106 - val_loss: 0.5790 - val_acc: 0.7845\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.5047 - acc: 0.8134 - val_loss: 0.5804 - val_acc: 0.7887\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4994 - acc: 0.8154 - val_loss: 0.5755 - val_acc: 0.7890\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4944 - acc: 0.8180 - val_loss: 0.5724 - val_acc: 0.7928\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4895 - acc: 0.8203 - val_loss: 0.5688 - val_acc: 0.7913\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.4849 - acc: 0.8219 - val_loss: 0.5661 - val_acc: 0.7920\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4802 - acc: 0.8240 - val_loss: 0.5644 - val_acc: 0.7930\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4759 - acc: 0.8259 - val_loss: 0.5624 - val_acc: 0.7975\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4718 - acc: 0.8281 - val_loss: 0.5594 - val_acc: 0.7960\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4677 - acc: 0.8302 - val_loss: 0.5582 - val_acc: 0.7977\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4638 - acc: 0.8316 - val_loss: 0.5554 - val_acc: 0.8012\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4600 - acc: 0.8348 - val_loss: 0.5567 - val_acc: 0.8025\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4567 - acc: 0.8366 - val_loss: 0.5539 - val_acc: 0.7982\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4533 - acc: 0.8369 - val_loss: 0.5516 - val_acc: 0.7990\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.4500 - acc: 0.8388 - val_loss: 0.5519 - val_acc: 0.7975\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.4466 - acc: 0.8409 - val_loss: 0.5493 - val_acc: 0.8037\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.4435 - acc: 0.8419 - val_loss: 0.5519 - val_acc: 0.8013\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4405 - acc: 0.8427 - val_loss: 0.5487 - val_acc: 0.8060\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4374 - acc: 0.8441 - val_loss: 0.5466 - val_acc: 0.8047\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4348 - acc: 0.8445 - val_loss: 0.5462 - val_acc: 0.8045\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4321 - acc: 0.8465 - val_loss: 0.5501 - val_acc: 0.8025\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4296 - acc: 0.8468 - val_loss: 0.5460 - val_acc: 0.8058\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4270 - acc: 0.8484 - val_loss: 0.5456 - val_acc: 0.8120\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4245 - acc: 0.8488 - val_loss: 0.5461 - val_acc: 0.8082\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.4219 - acc: 0.8504 - val_loss: 0.5497 - val_acc: 0.8040\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4197 - acc: 0.8507 - val_loss: 0.5435 - val_acc: 0.8107\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4173 - acc: 0.8513 - val_loss: 0.5436 - val_acc: 0.8068\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4151 - acc: 0.8510 - val_loss: 0.5422 - val_acc: 0.8063\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4129 - acc: 0.8529 - val_loss: 0.5403 - val_acc: 0.8107\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4108 - acc: 0.8542 - val_loss: 0.5432 - val_acc: 0.8060\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4086 - acc: 0.8553 - val_loss: 0.5456 - val_acc: 0.8047\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.4066 - acc: 0.8558 - val_loss: 0.5414 - val_acc: 0.8095\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.4043 - acc: 0.8558 - val_loss: 0.5448 - val_acc: 0.8053\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.4027 - acc: 0.8569 - val_loss: 0.5422 - val_acc: 0.8080\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.4008 - acc: 0.8568 - val_loss: 0.5415 - val_acc: 0.8115\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3992 - acc: 0.8586 - val_loss: 0.5422 - val_acc: 0.8125\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3973 - acc: 0.8581 - val_loss: 0.5419 - val_acc: 0.8103\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3954 - acc: 0.8591 - val_loss: 0.5412 - val_acc: 0.8123\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3936 - acc: 0.8603 - val_loss: 0.5433 - val_acc: 0.8130\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3924 - acc: 0.8605 - val_loss: 0.5427 - val_acc: 0.8098\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3905 - acc: 0.8612 - val_loss: 0.5456 - val_acc: 0.8115\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3888 - acc: 0.8623 - val_loss: 0.5421 - val_acc: 0.8100\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3873 - acc: 0.8623 - val_loss: 0.5464 - val_acc: 0.8093\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3861 - acc: 0.8636 - val_loss: 0.5424 - val_acc: 0.8125\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3842 - acc: 0.8645 - val_loss: 0.5426 - val_acc: 0.8127\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3826 - acc: 0.8639 - val_loss: 0.5452 - val_acc: 0.8112\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3814 - acc: 0.8643 - val_loss: 0.5434 - val_acc: 0.8090\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3800 - acc: 0.8647 - val_loss: 0.5464 - val_acc: 0.8085\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3785 - acc: 0.8653 - val_loss: 0.5434 - val_acc: 0.8113\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3771 - acc: 0.8660 - val_loss: 0.5427 - val_acc: 0.8115\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3757 - acc: 0.8667 - val_loss: 0.5466 - val_acc: 0.8072\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3745 - acc: 0.8675 - val_loss: 0.5485 - val_acc: 0.8097\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3731 - acc: 0.8675 - val_loss: 0.5451 - val_acc: 0.8110\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3718 - acc: 0.8679 - val_loss: 0.5445 - val_acc: 0.8115\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3708 - acc: 0.8684 - val_loss: 0.5459 - val_acc: 0.8098\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3693 - acc: 0.8694 - val_loss: 0.5458 - val_acc: 0.8110\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3683 - acc: 0.8698 - val_loss: 0.5493 - val_acc: 0.8107\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3665 - acc: 0.8702 - val_loss: 0.5467 - val_acc: 0.8103\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3658 - acc: 0.8701 - val_loss: 0.5492 - val_acc: 0.8093\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3644 - acc: 0.8710 - val_loss: 0.5501 - val_acc: 0.8097\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3633 - acc: 0.8710 - val_loss: 0.5506 - val_acc: 0.8105\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3622 - acc: 0.8713 - val_loss: 0.5495 - val_acc: 0.8118\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3610 - acc: 0.8720 - val_loss: 0.5492 - val_acc: 0.8080\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3600 - acc: 0.8728 - val_loss: 0.5528 - val_acc: 0.8095\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3588 - acc: 0.8724 - val_loss: 0.5530 - val_acc: 0.8105\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3581 - acc: 0.8738 - val_loss: 0.5508 - val_acc: 0.8095\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3565 - acc: 0.8739 - val_loss: 0.5506 - val_acc: 0.8103\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3557 - acc: 0.8735 - val_loss: 0.5531 - val_acc: 0.8060\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3548 - acc: 0.8737 - val_loss: 0.5516 - val_acc: 0.8125\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3535 - acc: 0.8744 - val_loss: 0.5539 - val_acc: 0.8120\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3524 - acc: 0.8750 - val_loss: 0.5534 - val_acc: 0.8100\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3514 - acc: 0.8758 - val_loss: 0.5569 - val_acc: 0.8127\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3505 - acc: 0.8757 - val_loss: 0.5605 - val_acc: 0.8102\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3495 - acc: 0.8758 - val_loss: 0.5623 - val_acc: 0.8093\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3486 - acc: 0.8760 - val_loss: 0.5558 - val_acc: 0.8115\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3475 - acc: 0.8768 - val_loss: 0.5596 - val_acc: 0.8060\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3466 - acc: 0.8774 - val_loss: 0.5564 - val_acc: 0.8070\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3455 - acc: 0.8777 - val_loss: 0.5586 - val_acc: 0.8127\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3445 - acc: 0.8776 - val_loss: 0.5581 - val_acc: 0.8093\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3435 - acc: 0.8784 - val_loss: 0.5617 - val_acc: 0.8085\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3429 - acc: 0.8783 - val_loss: 0.5602 - val_acc: 0.8080\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3416 - acc: 0.8783 - val_loss: 0.5606 - val_acc: 0.8055\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3408 - acc: 0.8791 - val_loss: 0.5613 - val_acc: 0.8093\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3401 - acc: 0.8795 - val_loss: 0.5627 - val_acc: 0.8075\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.3388 - acc: 0.8801 - val_loss: 0.5643 - val_acc: 0.8090\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3379 - acc: 0.8797 - val_loss: 0.5644 - val_acc: 0.8113\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3374 - acc: 0.8803 - val_loss: 0.5649 - val_acc: 0.8102\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3364 - acc: 0.8814 - val_loss: 0.5655 - val_acc: 0.8055\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3357 - acc: 0.8809 - val_loss: 0.5681 - val_acc: 0.8090\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3348 - acc: 0.8816 - val_loss: 0.5645 - val_acc: 0.8115\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3338 - acc: 0.8819 - val_loss: 0.5675 - val_acc: 0.8055\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3330 - acc: 0.8824 - val_loss: 0.5690 - val_acc: 0.8047\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3318 - acc: 0.8822 - val_loss: 0.5684 - val_acc: 0.8077\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3311 - acc: 0.8825 - val_loss: 0.5683 - val_acc: 0.8055\n",
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3304 - acc: 0.8836 - val_loss: 0.5725 - val_acc: 0.8078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3296 - acc: 0.8830 - val_loss: 0.5705 - val_acc: 0.8100\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3286 - acc: 0.8840 - val_loss: 0.5697 - val_acc: 0.8100\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3277 - acc: 0.8845 - val_loss: 0.5762 - val_acc: 0.8037\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3273 - acc: 0.8843 - val_loss: 0.5706 - val_acc: 0.8050\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 0.3261 - acc: 0.8853 - val_loss: 0.5785 - val_acc: 0.8022\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3253 - acc: 0.8852 - val_loss: 0.5754 - val_acc: 0.8055\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3246 - acc: 0.8849 - val_loss: 0.5760 - val_acc: 0.8053\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3236 - acc: 0.8857 - val_loss: 0.5781 - val_acc: 0.8082\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3230 - acc: 0.8860 - val_loss: 0.5729 - val_acc: 0.8060\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3221 - acc: 0.8859 - val_loss: 0.5763 - val_acc: 0.8060\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3213 - acc: 0.8862 - val_loss: 0.5745 - val_acc: 0.8057\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3204 - acc: 0.8869 - val_loss: 0.5789 - val_acc: 0.8040\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3196 - acc: 0.8868 - val_loss: 0.5770 - val_acc: 0.8062\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3187 - acc: 0.8872 - val_loss: 0.5774 - val_acc: 0.8067\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 0.3179 - acc: 0.8879 - val_loss: 0.5823 - val_acc: 0.8032\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 2s 30us/step - loss: 0.3172 - acc: 0.8875 - val_loss: 0.5825 - val_acc: 0.8088\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.3166 - acc: 0.8874 - val_loss: 0.5823 - val_acc: 0.8062\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3155 - acc: 0.8884 - val_loss: 0.5818 - val_acc: 0.8075\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3149 - acc: 0.8881 - val_loss: 0.5821 - val_acc: 0.8040\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3139 - acc: 0.8885 - val_loss: 0.5856 - val_acc: 0.8025\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3134 - acc: 0.8886 - val_loss: 0.5857 - val_acc: 0.8025\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3123 - acc: 0.8900 - val_loss: 0.5883 - val_acc: 0.8048\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3116 - acc: 0.8899 - val_loss: 0.5853 - val_acc: 0.8060\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3108 - acc: 0.8907 - val_loss: 0.5868 - val_acc: 0.8065\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3099 - acc: 0.8910 - val_loss: 0.6069 - val_acc: 0.7940\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3094 - acc: 0.8906 - val_loss: 0.5925 - val_acc: 0.8010\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3084 - acc: 0.8912 - val_loss: 0.5901 - val_acc: 0.8055\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3078 - acc: 0.8916 - val_loss: 0.5949 - val_acc: 0.8065\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3067 - acc: 0.8912 - val_loss: 0.5909 - val_acc: 0.8043\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 0.3056 - acc: 0.8924 - val_loss: 0.5914 - val_acc: 0.8070\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3053 - acc: 0.8922 - val_loss: 0.5920 - val_acc: 0.8042\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.3041 - acc: 0.8926 - val_loss: 0.5993 - val_acc: 0.8023\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 0.3038 - acc: 0.8929 - val_loss: 0.5934 - val_acc: 0.8053\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['acc'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 29us/step\n",
      "Training Loss: 0.299 \n",
      "Training Accuracy: 0.895\n",
      "----------\n",
      "4000/4000 [==============================] - 0s 31us/step\n",
      "Test Loss: 0.593 \n",
      "Test Accuracy: 0.805\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
